{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"Vickers-Chan-7thGraders_multiplex.edges\"\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "layer_graphs = {}\n",
    "G = nx.MultiGraph()\n",
    "for line in lines:\n",
    "    layer, node1, node2, weight = map(int, line.strip().split())\n",
    "    G.add_node(node1, layer=layer)\n",
    "    G.add_node(node2, layer=layer)\n",
    "    G.add_edge(node1, node2, layer=layer, weight=weight)\n",
    "    if layer not in layer_graphs:\n",
    "        layer_graphs[layer] = nx.MultiGraph()\n",
    "    layer_graphs[layer].add_edge(node1, node2, weight=weight)\n",
    "\n",
    "node_degrees = {}\n",
    "for layer, layer_graph in layer_graphs.items():\n",
    "    degrees = dict(layer_graph.degree())\n",
    "    node_degrees[layer] = degrees\n",
    "\n",
    "average_node_degrees = {}\n",
    "normalized_node_degree_counts = []\n",
    "for layer, degrees in node_degrees.items():\n",
    "    avg_degree = sum(degrees.values()) / len(degrees)\n",
    "    average_node_degrees[layer] = avg_degree\n",
    "\n",
    "degree_threshold_counts = []\n",
    "for layer, layer_graph in layer_graphs.items(): \n",
    "    degrees = node_degrees.get(layer, {})\n",
    "    avg_degree = average_node_degrees.get(layer, 0)\n",
    "    count = sum(1 for degree in degrees.values() if degree >= avg_degree)#节点度>平均度-1   向下取整\n",
    "    degree_threshold_counts.append(count)\n",
    "\n",
    "total_degree_threshold_count = sum(degree_threshold_counts)\n",
    "normalized_degree_threshold_counts = [count / total_degree_threshold_count for count in degree_threshold_counts]\n",
    "normalized_node_degree_counts_array = np.array(normalized_degree_threshold_counts)\n",
    "\n",
    "average_shortest_path_lengths = {}\n",
    "for layer, layer_graph in layer_graphs.items():\n",
    "    shortest_path_lengths = dict(nx.shortest_path_length(layer_graph, weight='weight'))\n",
    "    total_length = 0\n",
    "    total_pairs = 0\n",
    "    for node1 in layer_graph.nodes():\n",
    "        for node2 in layer_graph.nodes():\n",
    "            if node1 != node2:\n",
    "                if node2 not in shortest_path_lengths.get(node1, {}):\n",
    "                    length = 0\n",
    "                else:\n",
    "                    length = shortest_path_lengths[node1][node2]\n",
    "                total_length += length\n",
    "                total_pairs += 1\n",
    "    \n",
    "    avg_shortest_path_length = total_length / total_pairs if total_pairs > 0 else 0\n",
    "    average_shortest_path_lengths[layer] = avg_shortest_path_length\n",
    "    \n",
    "total_avg_shortest_path_length = sum(average_shortest_path_lengths.values())\n",
    "normalized_avg_shortest_path_lengths = []\n",
    "\n",
    "for layer, layer_graph in layer_graphs.items(): \n",
    "    length = average_shortest_path_lengths.get(layer, 0)\n",
    "    normalized_length = length / total_avg_shortest_path_length\n",
    "    normalized_avg_shortest_path_lengths.append(normalized_length)\n",
    "\n",
    "normalized_avg_shortest_path_lengths_array = np.array(normalized_avg_shortest_path_lengths)\n",
    "num_layers = len(layer_graphs)\n",
    "jaccard_coefficients = {}\n",
    "\n",
    "for layer in range(1, num_layers + 1):  \n",
    "    total_jaccard_coeff = 0\n",
    "    for other_layer in range(1, num_layers + 1): \n",
    "        if layer != other_layer:\n",
    "            intersection_size = len(set(layer_graphs[layer].edges()).intersection(layer_graphs[other_layer].edges()))\n",
    "            union_size = len(set(layer_graphs[layer].edges()).union(layer_graphs[other_layer].edges()))\n",
    "            jaccard_coeff = intersection_size / union_size if union_size > 0 else 0\n",
    "            total_jaccard_coeff += jaccard_coeff\n",
    "    jaccard_coefficients[layer] = total_jaccard_coeff\n",
    "\n",
    "total_jaccard_coeff_sum = sum(jaccard_coefficients.values())\n",
    "normalized_jaccard_coefficients = [coeff / total_jaccard_coeff_sum for coeff in jaccard_coefficients.values()]\n",
    "normalized_jaccard_coefficients_array = np.array(normalized_jaccard_coefficients)\n",
    "\n",
    "total_array = normalized_jaccard_coefficients_array + normalized_avg_shortest_path_lengths_array + normalized_node_degree_counts_array\n",
    "max_node_id = max(node_id for layer_graph in layer_graphs.values() for edge in layer_graph.edges() for node_id in edge)\n",
    "all_nodes = list(range(max_node_id + 1))\n",
    "\n",
    "k_shell_values = {}\n",
    "for layer, layer_graph in layer_graphs.items():\n",
    "    layer_graph.remove_edges_from(nx.selfloop_edges(layer_graph))\n",
    "    k_shell = nx.core_number(layer_graph)\n",
    "    k_shell_values[layer] = {node: k_shell.get(node, 0) for node in all_nodes}\n",
    "\n",
    "betweenness_centralities = {}\n",
    "for layer, layer_graph in layer_graphs.items():\n",
    "    betweenness_centrality = nx.betweenness_centrality(layer_graph)\n",
    "    betweenness_centralities[layer] = {node: betweenness_centrality.get(node, 0) for node in all_nodes}\n",
    "normalized_k_shell_values = {}\n",
    "\n",
    "for layer in k_shell_values:\n",
    "    unique_k_shell_values = list(set(k_shell_values[layer].values()))  \n",
    "    total_k_shell = sum(unique_k_shell_values)\n",
    "    normalized_k_shell_values[layer] = {node: k_shell_values[layer][node] / total_k_shell \n",
    "                                         for node in all_nodes if k_shell_values[layer][node] in unique_k_shell_values}\n",
    "normalized_betweenness_centralities = {}\n",
    "\n",
    "for layer in betweenness_centralities:\n",
    "    unique_betweenness_values = list(set(betweenness_centralities[layer].values()))\n",
    "    total_betweenness = sum(unique_betweenness_values)\n",
    "    \n",
    "    if total_betweenness > 0:\n",
    "        normalized_betweenness_centralities[layer] = {node: betweenness_centralities[layer][node] / total_betweenness \n",
    "                                                      for node in all_nodes if betweenness_centralities[layer][node] in unique_betweenness_values}\n",
    "    else:\n",
    "        normalized_betweenness_centralities[layer] = {node: 0 for node in all_nodes}\n",
    "layer_weights = total_array\n",
    "num_layers = len(layer_graphs)\n",
    "\n",
    "node_values = {}\n",
    "\n",
    "for node in all_nodes:\n",
    "    value = sum(\n",
    "        (normalized_k_shell_values[layer][node] + normalized_betweenness_centralities[layer][node]) * layer_weights[layer - 1]\n",
    "        for layer in range(1, num_layers + 1)\n",
    "        if node in normalized_k_shell_values[layer] and node in normalized_betweenness_centralities[layer]\n",
    "    )\n",
    "    node_values[node] = value\n",
    "\n",
    "node_values_array = np.array(list(node_values.values()))\n",
    "print(\"Node Values Array (Me):\")\n",
    "result_string = ','.join(map(str, node_values_array))\n",
    "print(result_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
